{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install azure-search-documents==11.4.0a20230509004\n",
    "! pip install openai\n",
    "! pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd  \n",
    "import os  \n",
    "import json  \n",
    "import openai  \n",
    "from dotenv import load_dotenv  \n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt  \n",
    "from azure.core.credentials import AzureKeyCredential  \n",
    "from azure.search.documents import SearchClient  \n",
    "from azure.search.documents.indexes import SearchIndexClient  \n",
    "from azure.search.documents.models import Vector  \n",
    "from azure.search.documents.indexes.models import (  \n",
    "    SearchIndex,  \n",
    "    SearchField,  \n",
    "    SearchFieldDataType,  \n",
    "    SimpleField,  \n",
    "    SearchableField,  \n",
    "    SearchIndex,  \n",
    "    SemanticConfiguration,  \n",
    "    PrioritizedFields,  \n",
    "    SemanticField,  \n",
    "    SearchField,  \n",
    "    SemanticSettings,  \n",
    "    VectorSearch,  \n",
    "    VectorSearchAlgorithmConfiguration,  \n",
    ")  \n",
    "  \n",
    "# Configure environment variables  \n",
    "load_dotenv()  \n",
    "service_endpoint = os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\")  \n",
    "index_name = os.getenv(\"AZURE_SEARCH_INDEX_NAME\")  \n",
    "key = os.getenv(\"AZURE_SEARCH_API_KEY\")  \n",
    "openai.api_type = \"azure\"  \n",
    "openai.api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")  \n",
    "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")  \n",
    "openai.api_version = os.getenv(\"OPENAI_API_VERSION\")  \n",
    "credential = AzureKeyCredential(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output_data/jsonQAdata.json', 'r', encoding='utf-8') as file:\n",
    "    input_data = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate embeddings for title and content fields, also used for query embeddings\n",
    "def generate_embeddings(text):\n",
    "    response = openai.Embedding.create(\n",
    "        input=text, engine=\"embed-testing\")\n",
    "    embeddings = response['data'][0]['embedding']\n",
    "    return embeddings\n",
    "\n",
    "for item in input_data:\n",
    "    title = item['question']\n",
    "    content = item['value']\n",
    "    title_embeddings = generate_embeddings(title)\n",
    "    content_embeddings = generate_embeddings(content)\n",
    "    item['titleVector'] = title_embeddings\n",
    "    item['contentVector'] = content_embeddings\n",
    "    item['@search.action'] = 'upload'\n",
    "\n",
    "# Output embeddings to docVectors.json file\n",
    "with open(\"output_data/docVectors.json\", \"w\") as f:\n",
    "    json.dump(input_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " vector-search-qai created\n"
     ]
    }
   ],
   "source": [
    "# Create a search index\n",
    "index_client = SearchIndexClient(\n",
    "    endpoint=service_endpoint, credential=credential)\n",
    "fields = [\n",
    "    SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True),\n",
    "    SearchableField(name=\"question\", type=SearchFieldDataType.String,\n",
    "                    searchable=True, retrievable=True),\n",
    "    SearchableField(name=\"value\", type=SearchFieldDataType.String,\n",
    "                    searchable=True, retrievable=True),\n",
    "    SearchField(name=\"titleVector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                searchable=True, dimensions=1536, vector_search_configuration=\"my-vector-config\"),\n",
    "    SearchField(name=\"contentVector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                searchable=True, dimensions=1536, vector_search_configuration=\"my-vector-config\"),\n",
    "]\n",
    "\n",
    "vector_search = VectorSearch(\n",
    "    algorithm_configurations=[\n",
    "        VectorSearchAlgorithmConfiguration(\n",
    "            name=\"my-vector-config\",\n",
    "            kind=\"hnsw\",\n",
    "            hnsw_parameters={\n",
    "                \"m\": 4,\n",
    "                \"efConstruction\": 400,\n",
    "                \"efSearch\": 1000,\n",
    "                \"metric\": \"cosine\"\n",
    "            }\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "semantic_config = SemanticConfiguration(\n",
    "    name=\"my-semantic-config\",\n",
    "    prioritized_fields=PrioritizedFields(\n",
    "        title_field=SemanticField(field_name=\"question\"),\n",
    "        prioritized_content_fields=[SemanticField(field_name=\"value\")]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create the semantic settings with the configuration\n",
    "semantic_settings = SemanticSettings(configurations=[semantic_config])\n",
    "\n",
    "# Create the search index with the semantic settings\n",
    "index = SearchIndex(name=index_name, fields=fields,\n",
    "                    vector_search=vector_search, semantic_settings=semantic_settings)\n",
    "result = index_client.create_or_update_index(index)\n",
    "print(f' {result.name} created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'error_map'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRequestEntityTooLargeError\u001b[0m                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\noahh\\anaconda3\\lib\\site-packages\\azure\\search\\documents\\_search_client.py:643\u001b[0m, in \u001b[0;36mSearchClient._index_documents_actions\u001b[1;34m(self, actions, **kwargs)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 643\u001b[0m     batch_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client\u001b[39m.\u001b[39mdocuments\u001b[39m.\u001b[39mindex(\n\u001b[0;32m    644\u001b[0m         batch\u001b[39m=\u001b[39mbatch, error_map\u001b[39m=\u001b[39merror_map, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    645\u001b[0m     )\n\u001b[0;32m    646\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(List[IndexingResult], batch_response\u001b[39m.\u001b[39mresults)\n",
      "File \u001b[1;32mc:\\Users\\noahh\\anaconda3\\lib\\site-packages\\azure\\core\\tracing\\decorator.py:76\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[39mif\u001b[39;00m span_impl_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 76\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     78\u001b[0m \u001b[39m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\noahh\\anaconda3\\lib\\site-packages\\azure\\search\\documents\\_generated\\operations\\_documents_operations.py:1268\u001b[0m, in \u001b[0;36mDocumentsOperations.index\u001b[1;34m(self, batch, request_options, **kwargs)\u001b[0m\n\u001b[0;32m   1267\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m200\u001b[39m, \u001b[39m207\u001b[39m]:\n\u001b[1;32m-> 1268\u001b[0m     map_error(status_code\u001b[39m=\u001b[39;49mresponse\u001b[39m.\u001b[39;49mstatus_code, response\u001b[39m=\u001b[39;49mresponse, error_map\u001b[39m=\u001b[39;49merror_map)\n\u001b[0;32m   1269\u001b[0m     error \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_deserialize\u001b[39m.\u001b[39mfailsafe_deserialize(_models\u001b[39m.\u001b[39mSearchError, pipeline_response)\n",
      "File \u001b[1;32mc:\\Users\\noahh\\anaconda3\\lib\\site-packages\\azure\\core\\exceptions.py:109\u001b[0m, in \u001b[0;36mmap_error\u001b[1;34m(status_code, response, error_map)\u001b[0m\n\u001b[0;32m    108\u001b[0m error \u001b[39m=\u001b[39m error_type(response\u001b[39m=\u001b[39mresponse)\n\u001b[1;32m--> 109\u001b[0m \u001b[39mraise\u001b[39;00m error\n",
      "\u001b[1;31mRequestEntityTooLargeError\u001b[0m: Operation returned an invalid status 'Request Entity Too Large'\nContent: The page was not displayed because the request entity is too large.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m search_client \u001b[39m=\u001b[39m SearchClient(endpoint\u001b[39m=\u001b[39mservice_endpoint, index_name\u001b[39m=\u001b[39mindex_name, credential\u001b[39m=\u001b[39mcredential)\n\u001b[0;32m     34\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m documentsAlpha:\n\u001b[1;32m---> 35\u001b[0m     result \u001b[39m=\u001b[39m search_client\u001b[39m.\u001b[39;49mupload_documents(x)  \n\u001b[0;32m     36\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUploaded \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(x)\u001b[39m}\u001b[39;00m\u001b[39m documents\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\noahh\\anaconda3\\lib\\site-packages\\azure\\search\\documents\\_search_client.py:544\u001b[0m, in \u001b[0;36mSearchClient.upload_documents\u001b[1;34m(self, documents, **kwargs)\u001b[0m\n\u001b[0;32m    541\u001b[0m batch\u001b[39m.\u001b[39madd_upload_actions(documents)\n\u001b[0;32m    543\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39mheaders\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_client_headers(kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mheaders\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m--> 544\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex_documents(batch, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    545\u001b[0m \u001b[39mreturn\u001b[39;00m cast(List[IndexingResult], results)\n",
      "File \u001b[1;32mc:\\Users\\noahh\\anaconda3\\lib\\site-packages\\azure\\core\\tracing\\decorator.py:76\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m span_impl_type \u001b[39m=\u001b[39m settings\u001b[39m.\u001b[39mtracing_implementation()\n\u001b[0;32m     75\u001b[0m \u001b[39mif\u001b[39;00m span_impl_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 76\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     78\u001b[0m \u001b[39m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[39mif\u001b[39;00m merge_span \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[1;32mc:\\Users\\noahh\\anaconda3\\lib\\site-packages\\azure\\search\\documents\\_search_client.py:635\u001b[0m, in \u001b[0;36mSearchClient.index_documents\u001b[1;34m(self, batch, **kwargs)\u001b[0m\n\u001b[0;32m    626\u001b[0m \u001b[39m@distributed_trace\u001b[39m\n\u001b[0;32m    627\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mindex_documents\u001b[39m(\u001b[39mself\u001b[39m, batch: IndexDocumentsBatch, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[IndexingResult]:\n\u001b[0;32m    628\u001b[0m     \u001b[39m\"\"\"Specify a document operations to perform as a batch.\u001b[39;00m\n\u001b[0;32m    629\u001b[0m \n\u001b[0;32m    630\u001b[0m \u001b[39m    :param batch: A batch of document operations to perform.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[39m    :raises :class:`~azure.search.documents.RequestEntityTooLargeError`\u001b[39;00m\n\u001b[0;32m    634\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 635\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_documents_actions(actions\u001b[39m=\u001b[39mbatch\u001b[39m.\u001b[39mactions, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\noahh\\anaconda3\\lib\\site-packages\\azure\\search\\documents\\_search_client.py:651\u001b[0m, in \u001b[0;36mSearchClient._index_documents_actions\u001b[1;34m(self, actions, **kwargs)\u001b[0m\n\u001b[0;32m    649\u001b[0m     \u001b[39mraise\u001b[39;00m\n\u001b[0;32m    650\u001b[0m pos \u001b[39m=\u001b[39m \u001b[39mround\u001b[39m(\u001b[39mlen\u001b[39m(actions) \u001b[39m/\u001b[39m \u001b[39m2\u001b[39m)\n\u001b[1;32m--> 651\u001b[0m batch_response_first_half \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_documents_actions(\n\u001b[0;32m    652\u001b[0m     actions\u001b[39m=\u001b[39mactions[:pos], error_map\u001b[39m=\u001b[39merror_map, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    653\u001b[0m )\n\u001b[0;32m    654\u001b[0m \u001b[39mif\u001b[39;00m batch_response_first_half:\n\u001b[0;32m    655\u001b[0m     result_first_half \u001b[39m=\u001b[39m cast(\n\u001b[0;32m    656\u001b[0m         List[IndexingResult], batch_response_first_half\u001b[39m.\u001b[39mresults\n\u001b[0;32m    657\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\noahh\\anaconda3\\lib\\site-packages\\azure\\search\\documents\\_search_client.py:643\u001b[0m, in \u001b[0;36mSearchClient._index_documents_actions\u001b[1;34m(self, actions, **kwargs)\u001b[0m\n\u001b[0;32m    641\u001b[0m batch \u001b[39m=\u001b[39m IndexBatch(actions\u001b[39m=\u001b[39mactions)\n\u001b[0;32m    642\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 643\u001b[0m     batch_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client\u001b[39m.\u001b[39mdocuments\u001b[39m.\u001b[39mindex(\n\u001b[0;32m    644\u001b[0m         batch\u001b[39m=\u001b[39mbatch, error_map\u001b[39m=\u001b[39merror_map, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    645\u001b[0m     )\n\u001b[0;32m    646\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(List[IndexingResult], batch_response\u001b[39m.\u001b[39mresults)\n\u001b[0;32m    647\u001b[0m \u001b[39mexcept\u001b[39;00m RequestEntityTooLargeError:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'error_map'"
     ]
    }
   ],
   "source": [
    "# Upload some documents to the index\n",
    "with open('output_data/docVectors.json', 'r') as file:  \n",
    "    documents = json.load(file)  \n",
    "\n",
    "documents1 = []\n",
    "documents2 = []\n",
    "documents3 = []\n",
    "documents4 = []\n",
    "documents5 = []\n",
    "documents6 = []\n",
    "j = 0\n",
    "\n",
    "for i in documents:\n",
    "    if j < 1000:\n",
    "        documents1.append(i)\n",
    "    if j < 2000:\n",
    "        documents2.append(i)\n",
    "    if j < 3000:\n",
    "        documents3.append(i)\n",
    "    if j < 4000:\n",
    "        documents4.append(i)\n",
    "    if j < 5000:\n",
    "        documents5.append(i)\n",
    "    else:\n",
    "        documents6.append(i)\n",
    "    j += 1\n",
    "\n",
    "documentsAlpha = [documents1, documents2, documents3, documents4, documents5, documents6]\n",
    "\n",
    "print(len(documents1))\n",
    "\n",
    "search_client = SearchClient(endpoint=service_endpoint, index_name=index_name, credential=credential)\n",
    "\n",
    "for x in documentsAlpha:\n",
    "    result = search_client.upload_documents(x)  \n",
    "    print(f\"Uploaded {len(x)} documents\") \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pure Vector Search\n",
    "query = \"Information about NetApp Cloud Manager\"  \n",
    "  \n",
    "search_client = SearchClient(service_endpoint, index_name, AzureKeyCredential(key))  \n",
    "  \n",
    "results = search_client.search(  \n",
    "    search_text=\"\",  \n",
    "    vector=Vector(value=generate_embeddings(query), k=3, fields=\"contentVector\"),  \n",
    "    select=[\"question\", \"value\"] \n",
    ")  \n",
    "  \n",
    "for result in results:  \n",
    "    print(f\"Encoded Question: {result['question']}\")  \n",
    "    print(f\"Score: {result['@search.score']}\")  \n",
    "    print(f\"Content: {result['value']}\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
